{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns # For creating plots\n",
    "\n",
    "from keras.models import Sequential, Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout\n",
    "import os\n",
    "\n",
    "\n",
    "os.chdir('C:\\\\Users\\\\s114sing\\\\OneDrive - Nokia\\\\Training Material\\\\Hackathon\\\\telecom-customer')\n",
    "\n",
    "data = pd.read_csv('Telecom_Manipulated_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_Mean</th>\n",
       "      <th>mou_Mean</th>\n",
       "      <th>totmrc_Mean</th>\n",
       "      <th>da_Mean</th>\n",
       "      <th>ovrmou_Mean</th>\n",
       "      <th>ovrrev_Mean</th>\n",
       "      <th>vceovr_Mean</th>\n",
       "      <th>datovr_Mean</th>\n",
       "      <th>roam_Mean</th>\n",
       "      <th>change_mou</th>\n",
       "      <th>...</th>\n",
       "      <th>dwllsize</th>\n",
       "      <th>forgntvl</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>kid0_2</th>\n",
       "      <th>kid3_5</th>\n",
       "      <th>kid6_10</th>\n",
       "      <th>kid11_15</th>\n",
       "      <th>kid16_17</th>\n",
       "      <th>creditcd</th>\n",
       "      <th>eqpdays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>23.9975</td>\n",
       "      <td>219.25</td>\n",
       "      <td>22.500</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-157.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>361.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>57.4925</td>\n",
       "      <td>482.75</td>\n",
       "      <td>37.425</td>\n",
       "      <td>0.2475</td>\n",
       "      <td>22.75</td>\n",
       "      <td>9.1</td>\n",
       "      <td>9.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>532.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>16.9900</td>\n",
       "      <td>10.25</td>\n",
       "      <td>16.990</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1504.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>7.50</td>\n",
       "      <td>38.000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1812.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>55.2300</td>\n",
       "      <td>570.50</td>\n",
       "      <td>71.980</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.50</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>434.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_Mean  mou_Mean  totmrc_Mean  da_Mean  ovrmou_Mean  ovrrev_Mean  \\\n",
       "0   23.9975    219.25       22.500   0.2475         0.00          0.0   \n",
       "1   57.4925    482.75       37.425   0.2475        22.75          9.1   \n",
       "2   16.9900     10.25       16.990   0.0000         0.00          0.0   \n",
       "3   38.0000      7.50       38.000   0.0000         0.00          0.0   \n",
       "4   55.2300    570.50       71.980   0.0000         0.00          0.0   \n",
       "\n",
       "   vceovr_Mean  datovr_Mean  roam_Mean  change_mou  ...  dwllsize  forgntvl  \\\n",
       "0          0.0          0.0        0.0     -157.25  ...         1       0.0   \n",
       "1          9.1          0.0        0.0      532.25  ...         1       0.0   \n",
       "2          0.0          0.0        0.0       -4.25  ...         1       0.0   \n",
       "3          0.0          0.0        0.0       -1.50  ...         4       0.0   \n",
       "4          0.0          0.0        0.0       38.50  ...        15       0.0   \n",
       "\n",
       "   ethnic  kid0_2  kid3_5  kid6_10  kid11_15  kid16_17  creditcd  eqpdays  \n",
       "0      10       1       1        1         1         1         2    361.0  \n",
       "1      17       1       1        1         1         1         2    240.0  \n",
       "2      10       1       2        1         1         1         2   1504.0  \n",
       "3      15       2       1        1         1         1         2   1812.0  \n",
       "4       7       1       1        1         1         1         2    434.0  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data\n",
    "df = df.drop(\"Customer_ID\",1)\n",
    "#df[\"churn\"] = data.target\n",
    "X = df.drop(\"churn\",1)   #Feature Matrix\n",
    "#X = df.drop(\"Customer_ID\",1)\n",
    "Y = df[\"churn\"]          #Target Variable\n",
    "#df = df.drop(\"Customer_ID\",1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s114sing\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-745314da70b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_constant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Fitting sm.OLS model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOLS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpvalues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "#Adding constant column of ones, mandatory for sm.OLS model\n",
    "X_1 = sm.add_constant(X)\n",
    "#Fitting sm.OLS model\n",
    "model = sm.OLS(y,X_1).fit()\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation with output variable\n",
    "cor_target = abs(cor[\"churn\"])\n",
    "\n",
    "#Selecting highly correlated features\n",
    "relevant_features = cor_target[cor_target>0.4]\n",
    "relevant_features_length = len(relevant_features)\n",
    "print(relevant_features)\n",
    "print(relevant_features_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cor_data = data[['mou_Mean','totmrc_Mean','plcd_vce_Mean',\"recv_vce_Mean\", 'comp_vce_Mean','mou_cvce_Mean','hnd_price','mou_rvce_Mean','owylis_vce_Mean','iwylis_vce_Mean','peak_vce_Mean','mou_peav_Mean','opk_vce_Mean','mou_opkv_Mean','attempt_Mean','complete_Mean','avg3mou','avg3qty','avg6mou','models','eqpdays']].to_numpy()\n",
    "#cor_data = data[['mou_Mean','totmrc_Mean','change_mou','unan_vce_Mean','plcd_vce_Mean',\"recv_vce_Mean\", 'comp_vce_Mean','custcare_Mean','ccrndmou_Mean','cc_mou_Mean','inonemin_Mean','threeway_Mean','mou_cvce_Mean','hnd_price','mou_rvce_Mean','owylis_vce_Mean','iwylis_vce_Mean','mouowylisv_Mean','peak_vce_Mean','mou_peav_Mean','opk_vce_Mean','mou_opkv_Mean','attempt_Mean','complete_Mean','callwait_Mean','uniqsubs','avg3mou','avg3qty','avg6mou','avg6qty','phones','models','lor','eqpdays']].to_numpy()\n",
    "#cor_data = data[['mou_Mean','totmrc_Mean','comp_vce_Mean','mou_cvce_Mean','complete_Mean','hnd_price','eqpdays']].to_numpy()\n",
    "cor_data = data[['uniqsubs','phones','drop_vce_Mean','models','drop_blk_Mean','roam_Mean','hnd_price','eqpdays']].to_numpy()\n",
    "print(cor_data)\n",
    "\n",
    "print(cor_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a Matrix 100000,22\n",
    "#nArr2D = np.empty([100000,22])\n",
    "#for i in range(relevant_features_length):  \n",
    "    #print(relevant_features.index[i])\n",
    " #   col = relevant_features.index[i]\n",
    "   #print(data[col])\n",
    "  #  nArr2D[i] = data[col]\n",
    "    #np.copy(nArr2D[i].data,data[col].data)\n",
    "    #data[col].data\n",
    "    #cor_data = data[col]\n",
    "\n",
    "#print(nArr2D.shape)\n",
    "#print(nArr2D)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deep learning Algorithim\n",
    "Y = data['churn'].values #churn values to be predicted  \n",
    "X = cor_data\n",
    "\n",
    "# Create Train & Test Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "visible = Input(shape=(2,))\n",
    "hidden1 = Dense(2, activation='relu')(visible)\n",
    "hidden2 = Dense(2, activation='relu')(hidden1)\n",
    "hidden3 = Dense(2, activation='relu')(hidden2)\n",
    "#hidden4 = Dense(15, activation='relu')(hidden3)\n",
    "output = Dense(1, activation='sigmoid')(hidden3)\n",
    "model = Model(inputs=visible, outputs=output)\n",
    "# summarize layers\n",
    "print(model.summary())\n",
    "# plot graph\n",
    "plot_model(model, to_file='multilayer_perceptron_graph.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "            loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train,\n",
    "          epochs=100,batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(X_test, Y_test)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "\n",
    "Y = data['churn'].values\n",
    "X = data.drop(columns= ['churn'])\n",
    "\n",
    "#Y = data['churn'].values #churn values to be predicted  \n",
    "#X = cor_data\n",
    "\n",
    "# Create Train & Test Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "np.shape(X_train)\n",
    "\n",
    "# Scaling all the variables to a range of 0 to 1\n",
    "\n",
    "#from sklearn.preprocessing import MinMaxScaler\n",
    "#features = X.columns.values\n",
    "#scaler = MinMaxScaler(feature_range = (0,1))\n",
    "#scaler.fit(X)\n",
    "#X = pd.DataFrame(scaler.transform(X))\n",
    "#X.columns = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running logistic regression model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "result = model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "prediction_test = model.predict(X_test)\n",
    "# Print the prediction accuracy\n",
    "print (metrics.accuracy_score(Y_test, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the weights of all the variables\n",
    "weights = pd.Series(model.coef_[0],index=X.columns.values)\n",
    "print (weights.sort_values(ascending = False)[:10].plot(kind='bar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "model_rf = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,\n",
    "#                                  random_state =50, max_features = \"auto\",\n",
    "#                                  max_leaf_nodes = 30)\n",
    "model_rf.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions\n",
    "prediction_test = model_rf.predict(X_test)\n",
    "print (metrics.accuracy_score(y_test, prediction_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importances = model_rf.feature_importances_\n",
    "weights = pd.Series(importances,index=X.columns.values)\n",
    "weights.sort_values()[-10:].plot(kind = 'barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
